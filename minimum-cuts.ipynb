{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 2-Min-Cut Problem\n",
    "\n",
    "Given any multigraph, we can partition its vertices into two sets. Such a partition leaves edges that cross from one set into the other. Those crossing edges shall be called the cut edges, or simply the cut. There are, of course, many cuts but we seek  the minimum. The question is: how does one partition a graph so as to minimize the number of edges in a cut? Correspondingly, with weighted edges, how does one minimize the sum of weights for a cut? For thinking about problems involving graph cuts like this I've found it useful to think of cuts akin to string figure games, like [cat's cradle](http://fun-party-games.com/cats-cradle.htm), where the hands can pull vertices apart into two sections and the edges between the sets hang between the fingers.\n",
    "![cats cradle](http://upload.wikimedia.org/wikipedia/commons/d/de/Cats-cradle.svg \"the strings between are the cut edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karger's Contraction Method\n",
    "\n",
    "In 1992, David Karger introduced the probabilistic contraction method for finding min-cuts in his paper [*Global Min-cuts in RNC*](http://dl.acm.org/citation.cfm?id=313605). His algorithm proceeds as follows: until only two *meta-*vertices remain, pick an edge uniformly at random and merge the two incident vertices of the edge. The motivation is simple: evident merely by the title *minimum cut*, the number of edges within any min-cut is likely to be small. Hence, there should be a high probability that after many contractions, edges in the minimum cut were not contracted. Specifically, to contract an edge $(u, v)$ create a new vertex $w$ and define its neighbors to be the multiset sum of of $u$ and $v$'s neighbors. Except in that sum we do not include edges between $u$ and $v$, in order to remove self-loops. See, that meta-vertices formed from contraction become the partition of the original vertices. In the figure below, [Thore Hysfeldt](http://thorehusfeldt.net/2012/09/07/images-for-kargers-algorithm/) has made some illustrative contractions: \n",
    "![contraciton examples](http://upload.wikimedia.org/wikipedia/commons/e/e7/Single_run_of_Karger%E2%80%99s_Mincut_algorithm.svg \"Thore Husfeldt's contraction examples\")\n",
    "\n",
    "In the text to follow, I make extensive use of insight from Karger's latter 1996 paper [*A New Approach to the Minimum Cut Problem*](http://www.columbia.edu/~cs2035/courses/ieor6614.S09/Contraction.pdf). I found it quite helpful in understanding all aspects of the algorithm and its generalizations. Let us now prove the claim that with high probability, the no edges in a min-cut will be contracted. For now we assume that the graph is unweighted. The weighted case will follow quite simply afterward. First, suppose that the minimum size cut has $c$ edge crossings. There may be many cuts that have this size, but we look only at one without loss of generality. When contracting the graph, we will come to a point where only $k$ vertices remain. The min-cut size of this contracted graph must be at least $c$ by the definition of the original min-cut. So, the minimum degree of the graph with $k$ vertices is $c$. Thus, the graph will have at least $kc/2$ edges. But, only $c$ of those edges are part of the minimum cut. Hence, the probability of choosing a min-cut edge in the contraction is $2/k$. Now, we make $n - 2$ contractions, for an original graph of size $n$, until just 2 meta-vertices or partitioned sets remain. Each contraction reduces the number of edges in the graph by 1. So, the probability that no min-cut edges are contracted in the whole run of the algorithm is:\n",
    "\n",
    "$$\\left(1 - \\frac{2}{n}\\right)\\left(1 - \\frac{2}{n-1}\\right)\\cdots\\left(1 - \\frac{2}{3}\\right) = \\binom{n}{2}^{-1} = \\Omega(n^{-2})$$ \n",
    "\n",
    "And there it is! That's a pretty good bound. And if we repeat the algorithm a bunch of times, say like $2\\binom{n}{2}\\ln(n)$ times then the probability of incorrectly contracting at least one min-cut edge every time is bounded as such:\n",
    "\n",
    "$$\\left(1-\\binom{n}{2}^{-1}\\right)^{\\binom{n}{2}\\cdot2\\ln(n)} \\leq e^{-2\\ln(n)} = \\frac{1}{n^2}$$\n",
    "\n",
    "Now, to apply this to weighted graphs see that we can map the weights to a number of parallel edges. In this construction, the probability of contracting one of those parallel edges is proportional to the weight of the original edgeâ€”and the contract of one of those parallel edges has the same effect as contraction for the weighted edge. So the uniform picking simply turns into a weighted picking of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Karger's Algorithm\n",
    "\n",
    "Now, let's roughly implement this algorithm, such that we can use it on a distance matrix that represents how related any two indices are. Although the algorithm's description is quite simple, the actual implementation of it is a bit tricky. Particularly, the contraction bit. The input for our algorithm will be a distance matrix, and to contract we will push on vertex onto another, instead of creating a new vertex. This can be done by adding both the row and column of one vertex onto the other. This makes sense, as any weights represented in a column or row correspond directly to incident edges; and we want to move those incidences from one vertex to another.\n",
    "\n",
    "First, though, let's create a weighted choice method to aid a contraction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import accumulate\n",
    "from bisect import bisect\n",
    "from random import random\n",
    "\n",
    "def wchoice(ws):\n",
    "    cumdist = list(accumulate(ws))\n",
    "    x = cumdist[-1] * random()\n",
    "    return bisect(cumdist, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test it out to make sure it works. I've found the Python package [tabulate](https://pypi.python.org/pypi/tabulate) to be a little bit more easy to play around with than panda's DataFrame method for simple examples and quick checking. As a side note, see the changes for Python 3 below: first `range` has [replaced](http://stackoverflow.com/questions/15014310/why-is-there-no-xrange-function-in-python3) `xrange`; and second, as per [PEP 238](http://legacy.python.org/dev/peps/pep-0238/), (`/`) is reserved for float division now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index    rel. freq.\n",
      "-------  ------------\n",
      "      0        0.1014\n",
      "      1        0.1993\n",
      "      2        0.3007\n",
      "      3        0.3987\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "\n",
    "ws = [0.1, 0.2, 0.3, 0.4]\n",
    "trials = 10**5\n",
    "c = Counter(wchoice(ws) for _ in range(trials))    # only Count a generator instead of a list to save memory\n",
    "rfreqs = [(k, round(v/trials, 4)) for k, v in c.items()]\n",
    "print(tabulate(rfreqs, headers=['index', 'rel. freq.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, it may be the case that there are no edges connecting two vertices in the distance matrix. If this is the case then when `wchoice` returns an index from the weights list referrring to that index of non-zero weights in the upper triangular matrix. Because there are possibly irregular zero values, those non-zero edges' indices must be stored ahead of time, such that we can return the index for the choice. Thus, there would be two passes through the upper indices, once to store indices of the edges and thier weights, and then another to calculate the weighted choice. That method, however, also requires $o(n^2)$ memory. Another option, is to run through only once, applying the king of the hill weighted choice method. As Eli Bendersky [points out](http://eli.thegreenplace.net/2010/01/22/weighted-random-generation-in-python/) in a blog post this method can be applied to a stream of incoming weights, where we may not know how many non-zero entries there are. This is exactly the kind of weighted choice that we seek; although it has the draw back of being a bit slower. Let's quickly implement it. Also it will help to define an upper triangular index generator for a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index      rel. freq.\n",
      "-------  ------------\n",
      "(0, 1)        0.09886\n",
      "(1, 2)        0.19879\n",
      "(2, 3)        0.30006\n",
      "(1, 3)        0.40229\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def utri(n, offset=1):\n",
    "    '''Generates tuples of indices i, j for the upper triangular portion of an n x n matrix.\n",
    "    The offset dicates how far the columns should start counting after the diagonal: offset=0.\n",
    "    '''\n",
    "    for i in range(n):\n",
    "        for j in range(i + offset, n):\n",
    "            yield i, j\n",
    "            \n",
    "# example distance matrix\n",
    "dm = np.array([[0, .1, 0, 0],\n",
    "               [.1, 0, .2, .4],\n",
    "               [0, .2, 0, .3],\n",
    "               [0, .4, .3, 0]])\n",
    "\n",
    "def king_hill(dm):\n",
    "    total = 0\n",
    "    for i, j in utri(len(dm)):\n",
    "        w = dm[i, j]\n",
    "        if w > 0:\n",
    "            total += w\n",
    "            if random() * total < w:\n",
    "                winner = i, j\n",
    "    return winner\n",
    "\n",
    "# we perform another quick check on the correctness of this weighted choice\n",
    "trials = 10**5\n",
    "c = Counter(king_hill(dm) for _ in range(trials))\n",
    "rfreqs = [(str(k), v/trials) for k, v in c.items()]\n",
    "rfreqs = sorted(rfreqs, key=lambda e: e[1])\n",
    "print(tabulate(rfreqs, headers=['index', 'rel. freq.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the `contract` method and `karger` method. Here's how they'll work: `contract` will take in a distance matrix, randomly pick an edge wrt the weights and contract them. It will then return the row and column of its edge selection, and return the new contracted distance matrix. The method `karger` will also take in a distance matrix, and runs the `contract` method until only 2 meta-vertices remain. It accumulates the selected edges returned by `contract`, so as to keep track of the cut's partition of the vertices. This whole process will be run $q\\binom{n}{2}\\ln{n}$ many times, where $q$ the exponent to get an error rate of $n^{-q}$ by the analysis above. For all these trials it will keep track of the most minimum cut weight, and return the minimum found with the corresponding partition of the indices. We can do more than just this though, Karger's implementation will actually return all min-cuts with high probability. Furthermore, if this method was used to divide objects into maximally different sets, where the distance matrix represented similarities between objects, then it may be the case that some choice will want to be done on the available cuts. That is, although a cut might have minimum value, there may be some conditions put onto the partition itself, such that the second minimum cut will actually work better. For all these reasons we implement the method with a heap, and then return the top $n$ cuts values along with one representative partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "import heapq\n",
    "            \n",
    "def contract(dm):\n",
    "    n = dm.shape[0]\n",
    "    total = 0\n",
    "    winner = None\n",
    "    for i, j in utri(n):\n",
    "        w = dm[i, j]\n",
    "        if w > 0:\n",
    "            total += w\n",
    "            if random() * total < w:\n",
    "                winner = i, j\n",
    "    i, j = winner\n",
    "    dm[i,:] += dm[j,:]\n",
    "    dm[:,i] += dm[j,:]        # reference dm[j,:] not dm[:,j] as the latter might have changed\n",
    "    dm[i,i] = 0\n",
    "    dm[j,:] = np.zeros(n)\n",
    "    dm[:,j] = np.zeros(n)\n",
    "    return (i, j), dm\n",
    "\n",
    "def karger(dm, q=2, topn=3):\n",
    "    n = dm.shape[0]\n",
    "    trials = int(n*(n-1)/2 * q * log(n))        # yields Omega(n^-q) error, with exponent q\n",
    "    heap = []\n",
    "    cuts = {}\n",
    "    for _ in range(trials):\n",
    "        dmc = np.copy(dm)\n",
    "        part = set()        # temp variable for cut set\n",
    "        for _ in range(n - 2):\n",
    "            ix, dmc = contract(dmc)\n",
    "            i, j = ix\n",
    "            if i in part or j in part or len(part) == 0:        # add i, j to appropriate partition\n",
    "                part.add(i), part.add(j)\n",
    "        cut_weight = np.sum(dmc)/2        # only count edge weights once\n",
    "        if frozenset(part) not in cuts:\n",
    "            heapq.heappush(heap, (cut_weight, part))\n",
    "            cuts[frozenset(part)] = (cut_weight, part)\n",
    "    return heapq.nsmallest(topn, heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could test this algorithm via a brute force approach, but see that it would entail finding all partitions into 2 sets. The problem of finding all partitions into $r$ parts is a difficult one. Knuth covers it in TAOCP Vol. 4: *Combinatorial Algorithms*, specifically [sections 7.2.1.4-5](http://www.cs.utsa.edu/~wagner/knuth/). For now, however, we shall relay the partition topic and the algorithm testing to [another notebook](http://www.google.com). From that notebook, though, we call non-empty subsets that define a partition of a set *blocks*. And from here on out, that is what they shall explicitly called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The $k$-Min-Cut Problem\n",
    "\n",
    "The contraction method described above can also be adapted for any $r$-cut in general. If we stop the contraction until $r$ meta-vertices remain then it turns out that, again, we have have a high probability of never cutting min-cut edges. And that's exactly what we want. As a side note, the cat's cradle analogy works for general $r$-cuts as well, all you need are other friend's hands: ![r-cut cat's cradle](http://youthvoices.net/sites/default/files/image/55246/oct/cats-cradle-8.png \"4-cut simulated by 4 hands in cat's cradle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalizing the contraction method\n",
    "\n",
    "First, just to clarify once more, the probabilistic analysis to follow has been learned from Karger's [*A New Approach to the Minimum Cut Problem*](http://www.columbia.edu/~cs2035/courses/ieor6614.S09/Contraction.pdf). Now to prove the contraction can be stopped early to generate a $r$ min-cut with high probability, let's first find the probability that a randomly picked edge from a graph with $n$ vertices is a min-cut edge. We use the probabilistic method, and construct a scenario where the probability of picking an edge in the min cut is clear: suppose we pick $r - 1$ vertices uniformly at random to create $r - 1$ singleton blocks with the remaining vertices defining the $r$<sup>th</sup> block. In this way we have defined an $r$-cut. Since an edge is in the cut if its vertices are in different blocks, then with this constuction an edges is in the cut if one of its vertices is in one of the $r - 1$ singleton blocks. This is simply the compliment of the chance that both of its vertices aren't in the $r - 1$ singleton blocks: \n",
    "\n",
    "$$1 - (1 - \\frac{r - 1}{n})(1 - \\frac{r - 1}{n - 1})$$ \n",
    "\n",
    "Next, we can now calculate the probability that a cut edge is never contracted. As calculated before, the probability of not picking a min-cut edge with $u$ edges is simply $(1 - \\frac{r - 1}{u})(1 - \\frac{r - 1}{u - 1})$. If we stop short with $r$ vertices remaining, each contraction reducing the size of the graph by one, then we will finally contract with a graph of size $r + 1$. The probability of never picking an edge from the cut set is then: \n",
    "\n",
    "$$ \\eqalign{\\prod_{u = r + 1}^n{ (1 - \\frac{r - 1}{u})(1 - \\frac{r - 1}{u - 1}) } &= \\\\ &= \\prod_{u = r + 1}^n{ (1 - \\frac{r - 1}{u}) }\\prod_{u = r + 1}^n{ (1 - \\frac{r - 1}{u - 1}) } &= \\\\ &= r\\binom{n}{r-1}^{-1}\\binom{n-1}{r-1}^{-1} \\\\ &= \\Omega(n^{-2(r-1)})}$$\n",
    "\n",
    "And there you have it. So, we can easily change the previous karger method to accommodate this; the best part being that the contraction method is exactly the same! Most of the change will occur with how the blocks are handled. When contracting an edge, to decide which block to put it in, we will keep a list of all pre-existing blocks. If the incident vertices of that edge are in a particular block then add it to that block, or if there aren't any blocks then create a first block. As we are trying to keep a heap, however, it will be cumbersome to check set existence in the dictionary for more than $r=2$ blocks. So, instead, let's have the algorithm just output restricted growth strings. This format is more heavily discussed in the notebook pertaining to the partition problem, [linked here](http://www.google.com) as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def karger2(dm, r, q=2, topn=3):\n",
    "    dm = np.array(dm)\n",
    "    n = len(dm)\n",
    "    trials = int(n*(n-1)/2 * q * log(n))        # yields Omega(n^-q) error, with exponent q\n",
    "    heap = []\n",
    "    cuts = {}\n",
    "    for _ in range(trials):\n",
    "        dmc = np.copy(dm)\n",
    "        rgs = [None] * n        # current restriced growth string\n",
    "        group = 0\n",
    "        for _ in range(n - r):\n",
    "            ix, dmc = contract(dmc)\n",
    "            i, j = ix\n",
    "            if rgs[i] == None and rgs[j] == None:\n",
    "                rgs[i] = group; rgs[j] = group\n",
    "                group += 1\n",
    "            elif rgs[i] != None:\n",
    "                rgs[j] = rgs[i]\n",
    "            elif rgs[j] != None:        # we use elif for clarity, but they both can't be None by construction\n",
    "                rgs[i] = rgs[j]\n",
    "        cut_weight = np.sum(dmc)/2        # only count edge weights once\n",
    "        for i in range(n):\n",
    "            if rgs[i] == None:        # assign remaining ungroup vertices\n",
    "                rgs[i] = group\n",
    "                group += 1\n",
    "        if tuple(rgs) not in cuts:\n",
    "            heapq.heappush(heap, (cut_weight, rgs))\n",
    "            cuts[tuple(rgs)] = (cut_weight, rgs)\n",
    "    return heapq.nsmallest(topn, heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Cuts\n",
    "\n",
    "Let's also create an easy way to visualize the cuts that the algorithm produces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACQCAYAAABNhSQEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nggcSCEHwQAIhCB7+HzC5webcfZgVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e9bc828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_cut(dm, part):\n",
    "    n = len(dm)\n",
    "    cut = set()\n",
    "    for i in range(0, n):\n",
    "        for j in range(i+1, n):\n",
    "            if dm[i, j] > 0 and (i in part) ^ (j in part):        # python xor\n",
    "                cut.add((i, j))\n",
    "    return cut\n",
    "\n",
    "# example distance matrix\n",
    "dm = np.random.rand(8, 8)\n",
    "for (i, j), x in np.ndenumerate(dm):\n",
    "    if random() < 0.8:\n",
    "        dm[i, j] = 0\n",
    "\n",
    "cut_weight, part = karger(dm)[0]\n",
    "cut = get_cut(dm, part)\n",
    "G = nx.from_numpy_matrix(dm)\n",
    "ecolors = ['gray' if e in cut else 'k' for e in G.edges()]\n",
    "estyles = ['dashed' if e in cut else 'solid' for e in G.edges()]\n",
    "plt.subplot(221)\n",
    "plt.title('hello')\n",
    "nx.draw_shell(G, node_color='salmon', edge_color=ecolors, width = 3, style=estyles)\n",
    "\n",
    "print(cut_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
